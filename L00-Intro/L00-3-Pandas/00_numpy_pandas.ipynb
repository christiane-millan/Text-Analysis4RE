{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    " \n",
    "__Contenido__\n",
    "\n",
    "* [Series](#series)\n",
    "* [DataFrames](#dataframes)\n",
    "* [CSV & JSON](#archivos-csv-y-json) \n",
    "\n",
    "\n",
    "Pandas está enfocada a la manipulación y análisis de datos.\n",
    "\n",
    "- Al estar construido sobre NumPy es veloz.\n",
    "- Requiere poco código para manipular los datos.\n",
    "- Soporta múltiples formatos de archivos.\n",
    "- Ordena los datos en una alienación inteligente.\n",
    "\n",
    "Se pueden manejar **grandes cantidades de datos**, hacer analítica y generar dashboards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Las `Series` son secuencias ordenadas de unidimensionales que pueden contener diferentes tipos de valores. En esto se parecen a las listas. De hecho podemos crear `Series` usando listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.Series(['Robert', 'Charly', 'George', 'Leo'], index=[1, 7, 10, 30])\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.Series(['Robert', 'Charly', 'George', 'Leo'])\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos incluso crear Series usando diccionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {1:'Robert', 7:'Charly', 10:'George', 30:'Leo'}\n",
    "pd.Series(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede crear una serie de pandas desde una lista, un diccionario o incluso un formato json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Series\n",
    "\n",
    "1.  Crear una Serie a partir de los nombres contenidos en cada una de las variables: `ejecutivo_`. Existe una variable `sueldos` que aun no ha sido asignada, tu reto consiste en asignar a la variable `sueldos` la información de dichos empleados.\n",
    "2. Una vez definidos los sueldos crea una Serie de manera que el el bloque de código que imprime los datos funcione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutivo_1 = 'Marco P.'\n",
    "ejecutivo_2 = 'Jenny'\n",
    "ejecutivo_3 = 'Britney Baby'\n",
    "ejecutivo_4 = 'Pepe Guardabosques'\n",
    "ejecutivo_5 = 'Lombardo El Destructor'\n",
    "\n",
    "sueldos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la Serie\n",
    "sueldos = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('== Sueldos de los principales ejecutivos de EyePoker Inc. ==\\n')\n",
    "\n",
    "print(f'{(\"Ejecutivo\"):25} | {(\"Sueldo\")}')\n",
    "print('----------------------------------------')\n",
    "print(f'{ejecutivo_1:25} | ${(sueldos.loc[ejecutivo_1])} MXN')\n",
    "print(f'{ejecutivo_2:25} | ${(sueldos.loc[ejecutivo_2])} MXN')\n",
    "print(f'{ejecutivo_3:25} | ${(sueldos.loc[ejecutivo_3])} MXN')\n",
    "print(f'{ejecutivo_4:25} | ${(sueldos.loc[ejecutivo_4])} MXN')\n",
    "print(f'{ejecutivo_5:25} | ${(sueldos.loc[ejecutivo_5])} MXN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "Los `DataFrames` son entonces estructuras de datos bidimensionales. Hay innumerables formas de crear `DataFrames`. Una forma simple es a apartir de un diccionario de listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Jugador' : ['Navas', 'Mbappe', 'Neymar', 'Messi'] , \n",
    "'Altura' : [183.0, 170.0, 170.0, 165.0], \n",
    "'Goles': [2, 200, 200, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players = pd.DataFrame(dict, index=[1, 7, 10, 30])\n",
    "df_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2. DataFrames\n",
    "\n",
    "A partir de los siguientes datos e índices que les corresponde, crear un `DataFrame` utilizando la variable `datos_producto` e `indice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_productos = {\n",
    "    \"nombre\": [\"Pokemaster\", \"Cegatron\", \"Pikame Mucho\", \"Lazarillo de Tormes\", \"Stevie Wonder\", \"Needle\", \"El AyMeDuele\"],\n",
    "    \"precio\": [10000, 5500, 3500, 750, 15500, 12250, 23000],\n",
    "    \"peso\": [1.2, 1.5, 2.3, 5.5, 3.4, 2.4, 8.8],\n",
    "    \"capacidad de destrucción retinal\": [3, 7, 6, 8, 9, 2, 10],\n",
    "    \"disponible\": [True, False, True, True, False, False, True]\n",
    "}\n",
    "\n",
    "indice = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivos CSV y JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('bestsellers-with-categories.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de un archivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hardware = pd.read_json('hpcharactersdataraw.json', typ='Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('hpcharactersdataraw.json', 'r')\n",
    "json_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "df = pd.DataFrame.from_dict(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación: loc & iloc\n",
    "\n",
    "Los método avanzados de indexación son utiles al momento de explorar y procesar datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[['Name', 'Author', 'Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.loc[0:4, ['Name', 'Author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.loc[:, ['Reviews']] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.loc[:, ['Author']] == 'JJ Smith'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[1, 3] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[:2, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3. Indexación\n",
    "\n",
    "Retomar el ejercicio 2. Ahora, indexa tu DataFrame para obtener los subconjuntos requeridos. Los productos en existencia tienen un orden específico en la base de datos. El orden correcto es el que está definido en `datos_productos`. Eso significa que el \"Pokemaster\" tiene el índice `1` y es el primer producto; y el \"El AyMeDuele\" tiene el ìndice `7` y es el último producto.\n",
    "\n",
    "Realiza las indexaciones debajo. Recuerda ordenar tus DataFrames en el orden en el que los menciona el Analista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero un DataFrame que contenga los productos \"Pikame Mucho\" y \"Stevie Wonder\"\n",
    "pm_sw =\n",
    "\n",
    "# Quiero un DataFrame que contenga desde el producto #4 hasta el último\n",
    "p4_final =\n",
    "\n",
    "# Quiero un DataFrame que contenga los productos \"El AyMeDuele\", \"Lazarillo de Tormes\" y \"Needle\"\n",
    "amd_lt_n =\n",
    "\n",
    "# Quiero un DataFrame que contenga desde el primer producto hasta el producto #5\n",
    "primer_p5 =\n",
    "\n",
    "# Quiero un DataFrame que contenga los productos \"Pikame Mucho\" y \"Lazarillo de Tormes\", pero sólo con las columnas \"nombre\", \"precio\" y \"peso\"\n",
    "pm_lt_pp =\n",
    "\n",
    "# Quiero un DataFrame que contenga todos los productos pero con sólo las columnas 'nombre', 'precio' y 'capacidad de destrucción retinal'\n",
    "t_pcdr =\n",
    "\n",
    "# Quiero un DataFrame que contenga desde el producto #3 hasta el #6, pero sólo las columnas 'nombre', 'precio' y 'disponible'\n",
    "p3_p6_pd ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar o eliminar datos con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df_books.drop('Genre', axis =1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.drop('Genre', axis= 1, inplace=True)\n",
    "# inplace borra la columna no solo en la salida, si no en el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = df_books.drop('Year', axis=1)\n",
    "# Otra forma de asegurarnos que drop afecte al df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_books['Price']\n",
    "# Es una función de python y no de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para borrar filas\n",
    "df_books.drop(0, axis=0).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.drop([0,1,2], axis=0).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.drop(range(0,10), axis=0).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas\n",
    "df_books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['New_column'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(0, df_books.shape[0])\n",
    "df_books['Range'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar filas\n",
    "df_books_new =pd.concat([df_books, df_books], ignore_index=True)\n",
    "df_books_new.reset_index()\n",
    "\n",
    "df_books_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Manipulación de columnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_productos = {\n",
    "    \"nombre\": [\"Pokemaster\", \"Cegatron\", \"Pikame Mucho\", \"Lazarillo de Tormes\", \"Stevie Wonder\", \"Needle\", \"El AyMeDuele\"],\n",
    "    \"precio\": [10000, 5500, 3500, 750, 15500, 12250, 23000],\n",
    "    \"peso\": [1.2, 1.5, 2.3, 5.5, 3.4, 2.4, 8.8],\n",
    "    \"capacidad de destrucción retinal\": [3, 7, 6, 8, 9, 2, 10],\n",
    "    \"disponible\": [True, False, True, True, False, False, True]\n",
    "}\n",
    "\n",
    "indice = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tareas a realizar: creación de una nueva columna, la asignación de nuevos datos a una columna y la eliminación de un par de columnas. Crea un DataFrame usando datos_productos e indice, realiza sus pedidos y envíalos para su verificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega por favor una nueva columna a `df_productos_mas_columna_nueva` con el nombre de columna \"nivel de dolor\"\n",
    "columna_nueva = [4, 7, 6, 8, 9, 7, 3]\n",
    "df_productos_mas_columna_nueva = df_productos.copy()\n",
    "\n",
    "# Cambia por favor el `DataFrame` `df_productos_descuento` cambiando la columna `precio` por la información contenida en `precios_descuento`\n",
    "precios_descuento = [8000, 4000, 2000, 500, 14000, 10000, 15000]\n",
    "df_productos_descuento = df_productos.copy()\n",
    "\n",
    "# Elimina por favor las columnas \"precio\" y \"peso\" de `df_productos` y asigna el resultado a `df_productos_sin_precio_ni_peso`\n",
    "df_productos_sin_precio_ni_peso ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict ={'col1': [1, 2, 3, np.nan],\n",
    " 'col2': [4, np.nan, 6, 7],\n",
    " 'col3': ['a', 'b', 'c', None]}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de NaNs por filas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    'precio': [34, 54, np.nan, np.nan, 56, 12, 34],\n",
    "    'cantidad_en_stock': [3, 6, 14, np.nan, 5, 2, 10],\n",
    "    'productos_vendidos': [3, 45, 23, np.nan, 24, 6, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(datos, index=[\"Pokemaster\", \"Cegatron\", \"Pikame Mucho\", \"Lazarillo de Tormes\", \"Stevie Wonder\", \"Needle\", \"El AyMeDuele\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar las filas que tengan mínimo 1 valor `NaN`, se utiliza `dropna(axis=0, how='any')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `axis=0` se elimina por filas. Con `how='any'` se elimina cualquier fila que tenga mínimo un `NaN`.\n",
    "\n",
    "Si se desea eliminar sólo las filas donde todos los valores sean NaN, podemos usar axis='all':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de NaNs por columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['descuento'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que por filas, eliminar `NaNs` por columna también se puede realizar utilizando `any` y `all`. La única diferencia es que se utiliza `axis=1` para eliminar por columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llenado de NaNs con valores \n",
    "\n",
    "Una estrategia común es llenar los valores NaN con algún valor, pare evitar eliminar datos.\n",
    "\n",
    "Por ejemplo, considerando el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero eliminar filas y columnas donde todos los valores sean NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nans = df.dropna(axis=0, how='all')\n",
    "df_no_nans = df_no_nans.dropna(axis=1, how='all')\n",
    "\n",
    "df_no_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, suponer que se asume que si hay un valor NaN en \"productos_vendidos\" es porque no ha sido vendido aún. En ese caso se puede rellenar el `NaN` usando `fillna`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nans['productos_vendidos'] = df_no_nans['productos_vendidos'].fillna(0)\n",
    "df_no_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, \"precio\" sí es una variable muy importante, así que nos deshacemos de las filas que aún tengan `NaNs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nans.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Identificación y limpieza de NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {\n",
    "    'precio': [12000, 5500, np.nan, 4800, 8900, np.nan, 1280, 1040, 23100, np.nan, 15000, 13400, np.nan],\n",
    "    'cantidad_en_stock': [34, 54, np.nan, 78, 56, np.nan, 34, 4, 0, 18, 45, 23, 5],\n",
    "    'cantidad_vendidos': [120, 34, np.nan, 9, 15, np.nan, 103, np.nan, np.nan, 23, 10, 62, 59],\n",
    "    'descuentos': [np.nan] * 13\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(datos, index=[\"Pokemaster\", \"Cegatron\", \"Pikame Mucho\", \"Lazarillo de Tormes\", \"Stevie Wonder\", \"Needle\", \"El AyMeDuele\", \"El Desretinador\", \"Sacamel Ojocles\", \"Desojado\", \"Maribel Buenas Noches\", \"Cíclope\", \"El Cuatro Ojos\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar los siguientes pasos para limpiar tu dataset:\n",
    "\n",
    "1. Hacer un conteo de cuántos `NaNs` hay en cada fila y en cada columna\n",
    "2. Elimina las filas y columnas donde todos los valores sean `NaN`.\n",
    "3. Dado que la columna `cantidad_vendidos` no es tan importante, cambiar los `NaNs` que haya en esa columna por 0.\n",
    "4. Dado que la columna `precio` es muy importante, eliminar las filas restantes que tengan algún `NaN` en dicha columna.\n",
    "\n",
    "Realizar todas tus transformaciones usando el `DataFrame` `df_copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "## Realiza aquí tus transformaciones\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado por condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('bestsellers-with-categories.csv', sep=',', header=0)\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['Year'] > 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_2016 = df_books['Year'] > 2016\n",
    "df_books[gt_2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[df_books['Year'] > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_fiction = df_books['Genre'] == 'Fiction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[genre_fiction & gt_2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[~gt_2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones principales de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo de los atributos numéricos\n",
    "df_books.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar que tanta memoria utiliza el dataframe, es conveniente iterarlo. o paralelizarlo\n",
    "df_books.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['Author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "df_books = df_books.append(df_books.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.concat([df_books, df_books.iloc[0:1]], ignore_index=True)\n",
    "df_books.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.sort_values('Year', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[['Author', 'User Rating', 'Reviews']].groupby('Author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').sum().loc['William Davis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby('Author').agg({'Reviews' : ['min', 'max'], 'User Rating' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.groupby(['Author', 'Year']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge y Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    " 'B': ['B0', 'B1', 'B2', 'B3'],\n",
    " 'C': ['C0', 'C1', 'C2', 'C3'],\n",
    " 'D': ['D0', 'D1', 'D2', 'D3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    " 'B': ['B4', 'B5', 'B6', 'B7'],\n",
    " 'C': ['C4', 'C5', 'C6', 'C7'],\n",
    " 'D': ['D4', 'D5', 'D6', 'D7']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq = pd.DataFrame({'key': ['k0', 'k1', 'k2', 'k3'],\n",
    "'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "der = pd.DataFrame({'key': ['k0', 'k1', 'k2', 'k3'],\n",
    "'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "'D': ['D0', 'D1', 'D2', 'D3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq = pd.DataFrame({'key': ['k0', 'k1', 'k2', 'k3'],\n",
    "'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "der = pd.DataFrame({'key2': ['k0', 'k1', 'k2', 'k3'],\n",
    "'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "'D': ['D0', 'D1', 'D2', 'D3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, left_on='key', right_on='key2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq = pd.DataFrame({'key': ['k0', 'k1', 'k2', 'k3'],\n",
    "'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "der = pd.DataFrame({'key2': ['k0', 'k1', 'k2', 'np.nan'],\n",
    "'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "'D': ['D0', 'D1', 'D2', 'D3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, left_on='key', right_on='key2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, left_on='key', right_on='key2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, left_on='key', right_on='key2', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.merge(der, left_on='key', right_on='key2', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "'B': ['B0', 'B1', 'B2']}, \n",
    "index=['k0', 'k1', 'k2'])\n",
    "\n",
    "der = pd.DataFrame({'C': ['C0', 'C1', 'C2'],\n",
    "'D': ['D0', 'D1', 'D2']},\n",
    "index= ['k0', 'k2', 'k3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.join(der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.join(der, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "izq.join(der, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot y Melt\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "## Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_times(value):\n",
    "    return value * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['User Rating'].apply(two_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mucho más eficiente que utilizar un for\n",
    "df_books['Rating_2'] = df_books['User Rating'].apply(two_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['Rating_2'] = df_books['User Rating'].apply(lambda x : x * 3)\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books['Rating_2'] = df_books.apply(lambda x : x['User Rating'] * 2 if x['Genre'] == 'Fiction' else x['User Rating'], axis=1)\n",
    "df_books.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "395a4e92152996666fb2f9ccdfaa123fbee5cdfd349ce9639909b685c816356c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
